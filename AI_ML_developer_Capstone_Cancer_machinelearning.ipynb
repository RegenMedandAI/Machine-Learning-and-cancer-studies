{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOD5R425QwH6mdsZaQly8Pl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RegenMedandAI/Machine-Learning-and-cancer-studies/blob/main/AI_ML_developer_Capstone_Cancer_machinelearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i am doing a machine learning study on breast cancer data from Kaggle, https://www.kaggle.com/datasets/brunogrisci/breast-cancer-gene-expression-cumida, the csv was edited in r to include Gene_symbol (gene name alongside the microarray probe ID) and the tumour grade. This generated the file Breast_GSE45827p.csv, from which the study proceeds. The microarray transcription data for breast cancer has sample cataagories of \"normal\", of tumor grade 0; \"Luminal_A\", of tumor grade 1; \"HER\", of tumor grade 3; \"basal\", of tumor grade 3; and \"Luminal B\", of luminal grade 2. The samples are in columns starting at column3, column name is sample number, the first row are the catagories and the second row are the grades. The first column are the gene list as probeID and the second column are the gene list as Gene_Symbol. The EDA consists of NAn check in the expression data, PCA analysis of the sample groups, a heatmap of the control genes to see if normalisation is needed"
      ],
      "metadata": {
        "id": "j2psL2ubDEGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data files available https://drive.google.com/drive/folders/1b2eMbXCYnf6sMYoJ8Eak4OjDGQmRXw-j?usp=sharing"
      ],
      "metadata": {
        "id": "5mrVFmbQvl_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3n4qp__yCxJz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#load the data\n",
        "data = pd.read_csv(\"Breast_GSE45827p.csv\")\n",
        "\n",
        "sample_ids = data.iloc[0, 2:153].index\n",
        "categories = data.iloc[0, 2:153]\n",
        "grades = data.iloc[1, 2:153]\n",
        "sample_info = pd.DataFrame({\n",
        "    'Sample_ID': sample_ids,\n",
        "    'Category': categories,\n",
        "    'Grade': grades\n",
        "})\n",
        "# Save the sample information to a CSV file\n",
        "sample_info.to_csv('sample_info.csv', index=False)\n",
        "\n",
        "# Extract gene information\n",
        "gene_info = data.iloc[2:, :2]\n",
        "gene_info.columns = ['ProbeID', 'GeneSymbol']\n",
        "gene_info.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Extract gene expression data\n",
        "expression_data = data.iloc[2:, 2:153]\n",
        "expression_data.columns = sample_ids\n",
        "expression_data.set_index(gene_info['ProbeID'], inplace=True)\n",
        "\n",
        "# Extract gene expression data\n",
        "expression_data = data.iloc[2:, 2:153]\n",
        "expression_data.columns = sample_ids\n",
        "\n",
        "# Check for and handle any remaining NaN values\n",
        "print(\"NaN values in expression data:\", expression_data.isna().sum().sum())\n",
        "\n",
        "# Transpose the data so that samples are rows and genes are columns\n",
        "expression_data_transposed = expression_data.T\n",
        "# Perform PCA\n",
        "scaler = StandardScaler()\n",
        "scaled_expression = scaler.fit_transform(expression_data_transposed)\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(scaled_expression)\n",
        "# Print PCA results shape\n",
        "print(\"PCA result shape:\", pca_result.shape)\n",
        "\n",
        "# # Create DataFrame for PCA results\n",
        "pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'], index=sample_ids)\n",
        "pca_df = pca_df.join(sample_info.set_index('Sample_ID'))\n",
        "# Print first few rows of PCA DataFrame\n",
        "print(\"\\nFirst few rows of PCA DataFrame:\")\n",
        "print(pca_df.head())\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create a figure with two subplots side by side\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot histogram of PC1\n",
        "sns.histplot(pca_df['PC1'], kde=True, ax=ax1)\n",
        "ax1.set_title('Distribution of PC1')\n",
        "ax1.set_xlabel('PC1 Values')\n",
        "\n",
        "# Plot histogram of PC2\n",
        "sns.histplot(pca_df['PC2'], kde=True, ax=ax2)\n",
        "ax2.set_title('Distribution of PC2')\n",
        "ax2.set_xlabel('PC2 Values')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create a figure with two subplots side by side\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot histogram of PC1\n",
        "sns.histplot(pca_df['PC1'], kde=True, ax=ax1)\n",
        "ax1.set_title('Distribution of PC1')\n",
        "ax1.set_xlabel('PC1 Values')\n",
        "\n",
        "# Plot histogram of PC2\n",
        "sns.histplot(pca_df['PC2'], kde=True, ax=ax2)\n",
        "ax2.set_title('Distribution of PC2')\n",
        "ax2.set_xlabel('PC2 Values')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PCA analysis showing tumour and grade\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "Breast_GSE45827p = pd.read_csv('Breast_GSE45827p.csv')\n",
        "\n",
        "# 1. Skip row numbering (data already has rownames)\n",
        "# 2. Extract relevant parts of the data\n",
        "sample_ids6 = Breast_GSE45827p.iloc[0, 2:].values  # Sample IDs in row 0 (excluding name)\n",
        "sample_grades6 = Breast_GSE45827p.iloc[1, 2:].values  # Sample types in row 1 (excluding name)\n",
        "probe_ids6 = Breast_GSE45827p.iloc[3:, 0].values         # Probe IDs starting from row 4 (index)\n",
        "gene_symbols6 = Breast_GSE45827p.iloc[3:, 1].values      # Gene symbols starting from row 4\n",
        "gene_expression6 = Breast_GSE45827p.iloc[3:, 2:].T    # Transpose to have samples as rows\n",
        "\n",
        "# 3. Print the first few sample types and grades\n",
        "print(\"First few sample types:\")\n",
        "print(sample_grades6[:5])\n",
        "\n",
        "\n",
        "# 4. Set row and column names for the gene expression matrix\n",
        "gene_expression6.columns = probe_ids6\n",
        "gene_expression6.index = sample_ids6\n",
        "\n",
        "# 5. Convert gene expression data to numeric\n",
        "gene_expression6 = gene_expression6.apply(pd.to_numeric)\n",
        "\n",
        "# 6. Perform PCA\n",
        "pca = PCA()\n",
        "pca_result6 = pca.fit_transform(gene_expression6)\n",
        "\n",
        "# 7. Extract PC1 and PC2\n",
        "pc_data6 = pd.DataFrame({\n",
        "    'PC1': pca_result6[:, 0],\n",
        "    'PC2': pca_result6[:, 1],\n",
        "    'Grade': sample_grades6,\n",
        "\n",
        "})\n",
        "\n",
        "# 8. Print the structure of pc_data6\n",
        "print(\"Structure of pc_data6:\")\n",
        "print(pc_data6.info())\n",
        "\n",
        "# 9. Calculate variance explained\n",
        "var_explained6 = pca.explained_variance_ratio_\n",
        "\n",
        "# 10. Plot PCA results colored by Grade\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='Grade', data=pc_data6, s=100, alpha=0.7)\n",
        "plt.title(f'PCA of Breast Cancer Gene Expression Data (Breast_GSE45827p) by Grade')\n",
        "plt.xlabel(f'PC1 ({var_explained6[0] * 100:.2f}% variance explained)')\n",
        "plt.ylabel(f'PC2 ({var_explained6[1] * 100:.2f}% variance explained)')\n",
        "plt.legend(title='Cancer Grade')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 12. Print summary of PCA\n",
        "print(\"PCA Summary:\")\n",
        "print(f\"Variance explained by first two components: PC1 = {var_explained6[0] * 100:.2f}%, PC2 = {var_explained6[1] * 100:.2f}%\")\n",
        "\n",
        "# 13. Display the first few rows of the PC data\n",
        "print(\"First few rows of PC data:\")\n",
        "print(pc_data6.head())\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "Breast_GSE45827p = pd.read_csv('Breast_GSE45827p.csv')\n",
        "\n",
        "# 1. Skip row numbering (data already has rownames)\n",
        "# 2. Extract relevant parts of the data\n",
        "sample_ids6 = Breast_GSE45827p.iloc[0, 2:].values  # Sample IDs in row 0 (excluding name)\n",
        "sample_types6 = Breast_GSE45827p.iloc[1, 2:].values  # Sample types in row 1 (excluding name)\n",
        "probe_ids6 = Breast_GSE45827p.iloc[3:, 0].values         # Probe IDs starting from row 3 (index)\n",
        "gene_symbols6 = Breast_GSE45827p.iloc[3:, 1].values      # Gene symbols starting from row 3\n",
        "gene_expression6 = Breast_GSE45827p.iloc[3:, 2:].T    # Transpose to have samples as rows\n",
        "\n",
        "# 3. Print the first few sample types\n",
        "print(\"First few sample types (Cancer types):\")\n",
        "print(sample_ids6[:5])\n",
        "\n",
        "\n",
        "# 4. Set row and column names for the gene expression matrix\n",
        "gene_expression6.columns = probe_ids6\n",
        "gene_expression6.index = sample_ids6\n",
        "\n",
        "# 5. Convert gene expression data to numeric\n",
        "gene_expression6 = gene_expression6.apply(pd.to_numeric)\n",
        "\n",
        "# 6. Perform PCA\n",
        "pca = PCA()\n",
        "pca_result6 = pca.fit_transform(gene_expression6)\n",
        "\n",
        "# 7. Extract PC1 and PC2\n",
        "pc_data6 = pd.DataFrame({\n",
        "    'PC1': pca_result6[:, 0],\n",
        "    'PC2': pca_result6[:, 1],\n",
        "    'Type': sample_ids6,\n",
        "    })\n",
        "\n",
        "# 8. Print the structure of pc_data6\n",
        "print(\"Structure of pc_data6:\")\n",
        "print(pc_data6.info())\n",
        "\n",
        "# 9. Calculate variance explained\n",
        "var_explained6 = pca.explained_variance_ratio_\n",
        "\n",
        "# 10. Plot PCA results colored by Type\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='Type', data=pc_data6, s=100, alpha=0.7)\n",
        "plt.title(f'PCA of Breast Cancer Gene Expression Data (Breast_GSE45827p) by Type')\n",
        "plt.xlabel(f'PC1 ({var_explained6[0] * 100:.2f}% variance explained)')\n",
        "plt.ylabel(f'PC2 ({var_explained6[1] * 100:.2f}% variance explained)')\n",
        "plt.legend(title='Cancer Type')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 12. Print summary of PCA\n",
        "print(\"PCA Summary:\")\n",
        "print(f\"Variance explained by first two components: PC1 = {var_explained6[0] * 100:.2f}%, PC2 = {var_explained6[1] * 100:.2f}%\")\n",
        "\n",
        "# 13. Display the first few rows of the PC data\n",
        "print(\"First few rows of PC data:\")\n",
        "print(pc_data6.head())"
      ],
      "metadata": {
        "id": "C_HvZxz_EY4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hierarchical Clustering with Heatmap of AFFX and controls, test whether data normalisation is required\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('Breast_GSE45827p.csv')\n",
        "\n",
        "# Extract sample data (columns 3 to 153, rows 3 to 54677) and convert to float\n",
        "sample_data = df.iloc[2:54677, 2:153].astype(float)\n",
        "\n",
        "# Extract probe IDs and gene symbols\n",
        "probe_ids = df.iloc[2:54677, 0]\n",
        "gene_symbols = df.iloc[2:54677, 1]\n",
        "\n",
        "# Extract sample names, types, and grades\n",
        "sample_names = df.columns[2:153]\n",
        "sample_types = df.iloc[0, 2:153]\n",
        "sample_grades = df.iloc[1, 2:153]\n",
        "\n",
        "# Filter for AFFX probes\n",
        "affx_mask = probe_ids.str.contains('AFFX', case=False, na=False)\n",
        "affx_data = sample_data[affx_mask]\n",
        "affx_probe_ids = probe_ids[affx_mask]\n",
        "\n",
        "# Create a DataFrame with AFFX probe data\n",
        "affx_df = pd.DataFrame(affx_data.values, index=affx_probe_ids, columns=sample_names)\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(20, 10))\n",
        "sns.heatmap(affx_df, cmap='coolwarm', center=0, cbar_kws={'label': 'Expression Value'})\n",
        "plt.title('Heatmap of AFFX Probes Across Samples')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('AFFX Probe IDs')\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print some statistics\n",
        "print(f\"Total number of AFFX probes: {len(affx_probe_ids)}\")\n",
        "print(\"\\nFirst 10 AFFX probe IDs:\")\n",
        "print(affx_probe_ids[:10].tolist())\n",
        "\n",
        "# Calculate and print average expression for each AFFX probe\n",
        "avg_expression = affx_df.mean(axis=1).sort_values(ascending=False)\n",
        "print(\"\\nTop 10 AFFX probes by average expression:\")\n",
        "print(avg_expression.head(10))\n",
        "\n",
        "print(\"\\nBottom 10 AFFX probes by average expression:\")\n",
        "print(avg_expression.tail(10))"
      ],
      "metadata": {
        "id": "Zpc2_lMpEi0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JhsZaL76Ew-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART2 Breast Cancer Gene Expression Analysis: Multi-Model Approach Overview This project implements a comprehensive machine learning analysis for breast cancer classification using gene expression data, employing three distinct modeling approaches to assess their ability to best identify cancer type and tumour grade.\n",
        "\n",
        "Random Forest (RF) Support Vector Machine (SVM) Deep Neural Network (DNN)\n",
        "\n",
        "Data Preprocessing\n",
        "\n",
        "Feature extraction from gene expression values Label encoding for cancer types and tumor grades Train-test split (80-20) StandardScaler application for feature normalization\n",
        "\n",
        "Model Architectures\n",
        "\n",
        "Random Forest Classifier\n",
        "Non-parametric, ensemble learning method Uses 100 decision trees (n_estimators=100) Advantages:\n",
        "\n",
        "Built-in feature importance Handles non-linearity effectively Less prone to overfitting\n",
        "\n",
        "Support Vector Machine\n",
        "Kernel: Linear and RBF (Radial Basis Function) Hyperparameters:\n",
        "\n",
        "probability=True for probability estimates random_state=42 for reproducibility\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Effective in high-dimensional spaces Memory efficient Versatile through different kernel functions\n",
        "\n",
        "Deep Neural Network\n",
        "Architecture:\n",
        "\n",
        "Input layer: Matches feature dimensionality Hidden layers: 256 → 128 → 64 neurons Output layer: Softmax activation\n",
        "\n",
        "Training parameters:\n",
        "\n",
        "Epochs: 100 Batch size: 32 Early stopping with patience=10\n",
        "\n",
        "Regularization techniques:\n",
        "\n",
        "Dropout (0.3) BatchNormalization\n",
        "\n",
        "Optimizer: Adam Loss function: Categorical crossentropy\n",
        "\n",
        "Model Comparison Similarities\n",
        "\n",
        "RF and SVM:\n",
        "\n",
        "Both are traditional machine learning algorithms Work well with high-dimensional data Less computational resources compared to DNN\n",
        "\n",
        "SVM and DNN:\n",
        "\n",
        "Both create hyperplanes for classification Can model non-linear relationships\n",
        "\n",
        "Key Differences\n",
        "\n",
        "Random Forest:\n",
        "\n",
        "Ensemble method using multiple decision trees Provides feature importance out-of-the-box May struggle with very high-dimensional data\n",
        "\n",
        "SVM:\n",
        "\n",
        "Creates optimal hyperplane for class separation Kernel trick for non-linear classification Can be computationally intensive for large datasets\n",
        "\n",
        "Deep Neural Network:\n",
        "\n",
        "Most complex model with multiple layers Requires more data for optimal performance Computationally intensive training Can automatically learn feature representations\n",
        "\n",
        "Comparative Efficacy The most appropriate model depends on specific requirements:\n",
        "\n",
        "For interpretability: Random Forest For balanced performance: SVM For complex pattern recognition: Deep Neural Network\n",
        "\n",
        "Implementation Notes\n",
        "\n",
        "Both cancer type and tumor grade classifications are performed All models use consistent preprocessing for fair comparison Early stopping in DNN prevents overfitting Multiple evaluation metrics: accuracy, classification report, confusion matrix"
      ],
      "metadata": {
        "id": "GDN1FDV7EydX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is designed for preprocessing breast cancer gene expression data in preparation for machine learning classification tasks. It involves loading the data, extracting features (gene expression values) and labels (cancer types and tumor grades), encoding categorical labels into numerical form, and splitting the dataset into training and testing sets. Additionally, feature scaling is performed to standardize the data, which helps improve model performance during classification of cancer types and tumor grades. The dataset used for this task is sourced from the Breast_GSE45827p.csv file, which contains gene expression profiles and associated clinical information.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('Breast_GSE45827p.csv')\n",
        "print(df.head()) # Use head() to display the first few rows of the dataframe\n",
        "\n",
        "#Corrected Data Preprocessing for Breast Cancer Gene Expression Analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "\n",
        "\n",
        "# Extract features (gene expression values)\n",
        "X = df.iloc[2:, 2:153].T  # Transpose to get samples as rows\n",
        "X.index = df.columns[2:153]  # Set sample names as index\n",
        "X.columns = df.iloc[2:, 0]  # Set probe_id as column names\n",
        "\n",
        "# Extract labels\n",
        "y_type = df.iloc[0, 2:153]\n",
        "y_grade = df.iloc[1, 2:153].astype(str)\n",
        "\n",
        "# Create a mapping of probe_id to gene symbol\n",
        "gene_map = dict(zip(df.iloc[2:, 0], df.iloc[2:, 1]))\n",
        "\n",
        "# Encode cancer types and grades\n",
        "le_type = LabelEncoder()\n",
        "le_grade = LabelEncoder()\n",
        "y_type_encoded = le_type.fit_transform(y_type)\n",
        "y_grade_encoded = le_grade.fit_transform(y_grade)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_type_train, y_type_test, y_grade_train, y_grade_test = train_test_split(\n",
        "    X, y_type_encoded, y_grade_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Data preprocessed and split into training and test sets.\")\n",
        "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
        "print(f\"Test set shape: {X_test_scaled.shape}\")\n",
        "print(f\"Cancer types: {le_type.classes_}\")\n",
        "print(f\"Tumor grades: {le_grade.classes_}\")"
      ],
      "metadata": {
        "id": "kTlC2gudFJrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine Learning Analysis for Breast Cancer Gene Expression Data- RANDOM CLASSIFIER\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Using the preprocessed data from previous code\n",
        "# Assuming we have: X_train_scaled, X_test_scaled, y_type_train, y_type_test, y_grade_train, y_grade_test\n",
        "\n",
        "# 1. Train and evaluate cancer type classifier\n",
        "rf_type = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_type.fit(X_train_scaled, y_type_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_type_pred = rf_type.predict(X_test_scaled)\n",
        "\n",
        "print(\"Cancer Type Classification Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_type_test, y_type_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_type_test, y_type_pred, target_names=le_type.classes_))\n",
        "\n",
        "# Confusion Matrix for cancer types\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_type = confusion_matrix(y_type_test, y_type_pred)\n",
        "sns.heatmap(cm_type, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le_type.classes_,\n",
        "            yticklabels=le_type.classes_)\n",
        "plt.title('Confusion Matrix - Cancer Types')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# 2. Train and evaluate tumor grade classifier\n",
        "rf_grade = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_grade.fit(X_train_scaled, y_grade_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_grade_pred = rf_grade.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nTumor Grade Classification Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_grade_test, y_grade_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_grade_test, y_grade_pred, target_names=le_grade.classes_))\n",
        "\n",
        "# Confusion Matrix for tumor grades\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_grade = confusion_matrix(y_grade_test, y_grade_pred)\n",
        "sns.heatmap(cm_grade, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le_grade.classes_,\n",
        "            yticklabels=le_grade.classes_)\n",
        "plt.title('Confusion Matrix - Tumor Grades')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# 3. Feature Importance Analysis\n",
        "# For cancer types\n",
        "feature_importance_type = pd.DataFrame({\n",
        "    'gene': X.columns,\n",
        "    'importance': rf_type.feature_importances_\n",
        "})\n",
        "feature_importance_type = feature_importance_type.sort_values('importance', ascending=False)\n",
        "\n",
        "# For tumor grades\n",
        "feature_importance_grade = pd.DataFrame({\n",
        "    'gene': X.columns,\n",
        "    'importance': rf_grade.feature_importances_\n",
        "})\n",
        "feature_importance_grade = feature_importance_grade.sort_values('importance', ascending=False)\n",
        "\n",
        "# Print top 10 important genes for each classification\n",
        "print(\"\\nTop 10 Important Genes for Cancer Type Classification:\")\n",
        "for i, row in feature_importance_type.head(10).iterrows():\n",
        "    gene_symbol = gene_map.get(row['gene'], row['gene'])\n",
        "    print(f\"{gene_symbol}: {row['importance']:.4f}\")\n",
        "\n",
        "print(\"\\nTop 10 Important Genes for Tumor Grade Classification:\")\n",
        "for i, row in feature_importance_grade.head(10).iterrows():\n",
        "    gene_symbol = gene_map.get(row['gene'], row['gene'])\n",
        "    print(f\"{gene_symbol}: {row['importance']:.4f}\")"
      ],
      "metadata": {
        "id": "dXGBk3A9FqUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM machine learning\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Data Loading and Preprocessing\n",
        "print(\"Loading and preprocessing data...\")\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('Breast_GSE45827p.csv')\n",
        "print(\"First few rows of the dataframe:\")\n",
        "print(df.head())\n",
        "\n",
        "# Extract features (gene expression values)\n",
        "X = df.iloc[2:, 2:153].T  # Transpose to get samples as rows\n",
        "X.index = df.columns[2:153]  # Set sample names as index\n",
        "X.columns = df.iloc[2:, 0]  # Set probe_id as column names\n",
        "\n",
        "# Extract labels\n",
        "y_type = df.iloc[0, 2:153]\n",
        "y_grade = df.iloc[1, 2:153].astype(str)\n",
        "\n",
        "# Create a mapping of probe_id to gene symbol\n",
        "gene_map = dict(zip(df.iloc[2:, 0], df.iloc[2:, 1]))\n",
        "\n",
        "# Encode cancer types and grades\n",
        "le_type = LabelEncoder()\n",
        "le_grade = LabelEncoder()\n",
        "y_type_encoded = le_type.fit_transform(y_type)\n",
        "y_grade_encoded = le_grade.fit_transform(y_grade)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_type_train, y_type_test, y_grade_train, y_grade_test = train_test_split(\n",
        "    X, y_type_encoded, y_grade_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\nData preprocessing completed:\")\n",
        "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
        "print(f\"Test set shape: {X_test_scaled.shape}\")\n",
        "print(f\"Cancer types: {le_type.classes_}\")\n",
        "print(f\"Tumor grades: {le_grade.classes_}\")\n",
        "\n",
        "# 2. Cancer Type Classification with SVM\n",
        "print(\"\\nTraining SVM for Cancer Type Classification...\")\n",
        "svm_type = SVC(kernel='linear', random_state=42)\n",
        "svm_type.fit(X_train_scaled, y_type_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_type_pred_svm = svm_type.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nCancer Type Classification Results (SVM):\")\n",
        "print(\"Accuracy:\", accuracy_score(y_type_test, y_type_pred_svm))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_type_test, y_type_pred_svm, target_names=le_type.classes_))\n",
        "\n",
        "# Confusion Matrix for cancer types (SVM)\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_type_svm = confusion_matrix(y_type_test, y_type_pred_svm)\n",
        "sns.heatmap(cm_type_svm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le_type.classes_,\n",
        "            yticklabels=le_type.classes_)\n",
        "plt.title('Confusion Matrix - Cancer Types (SVM)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# 3. Tumor Grade Classification with SVM\n",
        "print(\"\\nTraining SVM for Tumor Grade Classification...\")\n",
        "svm_grade = SVC(kernel='linear', random_state=42)\n",
        "svm_grade.fit(X_train_scaled, y_grade_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_grade_pred_svm = svm_grade.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nTumor Grade Classification Results (SVM):\")\n",
        "print(\"Accuracy:\", accuracy_score(y_grade_test, y_grade_pred_svm))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_grade_test, y_grade_pred_svm, target_names=le_grade.classes_))\n",
        "\n",
        "# Confusion Matrix for tumor grades (SVM)\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_grade_svm = confusion_matrix(y_grade_test, y_grade_pred_svm)\n",
        "sns.heatmap(cm_grade_svm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le_grade.classes_,\n",
        "            yticklabels=le_grade.classes_)\n",
        "plt.title('Confusion Matrix - Tumor Grades (SVM)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# 4. Feature Importance Analysis\n",
        "def get_svm_feature_importance(svm_model, feature_names, class_labels):\n",
        "    importance_per_class = {}\n",
        "    for i, class_label in enumerate(class_labels):\n",
        "        if len(class_labels) == 2 and i == 1:\n",
        "            continue\n",
        "        coef = svm_model.coef_[i] if len(class_labels) > 2 else svm_model.coef_[0]\n",
        "        importance = pd.DataFrame({\n",
        "            'gene': feature_names,\n",
        "            'importance': np.abs(coef)\n",
        "        })\n",
        "        importance_per_class[class_label] = importance.sort_values('importance', ascending=False)\n",
        "    return importance_per_class\n",
        "\n",
        "# Get feature importance for cancer types\n",
        "type_importance_svm = get_svm_feature_importance(svm_type, X.columns, le_type.classes_)\n",
        "\n",
        "print(\"\\nTop 10 Important Genes for Cancer Type Classification (SVM):\")\n",
        "for class_label, importance_df in type_importance_svm.items():\n",
        "    print(f\"\\nFor {class_label}:\")\n",
        "    for i, row in importance_df.head(10).iterrows():\n",
        "        gene_symbol = gene_map.get(row['gene'], row['gene'])\n",
        "        print(f\"{gene_symbol}: {row['importance']:.4f}\")"
      ],
      "metadata": {
        "id": "QgY4pSnRF4IS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network Analysis for Breast Cancer Gene Expression Data\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert labels to categorical format for Keras\n",
        "y_type_train_cat = to_categorical(y_type_train)\n",
        "y_type_test_cat = to_categorical(y_type_test)\n",
        "y_grade_train_cat = to_categorical(y_grade_train)\n",
        "y_grade_test_cat = to_categorical(y_grade_test)\n",
        "\n",
        "# 1. Define function to create model\n",
        "def create_model(input_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Dense(256, activation='relu', input_dim=input_dim),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(output_dim, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 2. Train and evaluate cancer type classifier\n",
        "print(\"Training Neural Network for Cancer Type Classification...\")\n",
        "nn_type = create_model(X_train_scaled.shape[1], len(le_type.classes_))\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "history_type = nn_type.fit(X_train_scaled, y_type_train_cat,\n",
        "                          validation_split=0.2,\n",
        "                          epochs=100,\n",
        "                          batch_size=32,\n",
        "                          callbacks=[early_stopping],\n",
        "                          verbose=1)\n",
        "\n",
        "# Evaluate cancer type model\n",
        "y_type_pred_nn = nn_type.predict(X_test_scaled)\n",
        "y_type_pred_classes = np.argmax(y_type_pred_nn, axis=1)\n",
        "\n",
        "print(\"\\nCancer Type Classification Results (Neural Network):\")\n",
        "print(\"Accuracy:\", accuracy_score(y_type_test, y_type_pred_classes))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_type_test, y_type_pred_classes, target_names=le_type.classes_))\n",
        "\n",
        "# Plot training history for cancer type\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_type.history['accuracy'])\n",
        "plt.plot(history_type.history['val_accuracy'])\n",
        "plt.title('Cancer Type Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_type.history['loss'])\n",
        "plt.plot(history_type.history['val_loss'])\n",
        "plt.title('Cancer Type Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Train and evaluate tumor grade classifier\n",
        "print(\"\\nTraining Neural Network for Tumor Grade Classification...\")\n",
        "nn_grade = create_model(X_train_scaled.shape[1], len(le_grade.classes_))\n",
        "\n",
        "history_grade = nn_grade.fit(X_train_scaled, y_grade_train_cat,\n",
        "                            validation_split=0.2,\n",
        "                            epochs=100,\n",
        "                            batch_size=32,\n",
        "                            callbacks=[early_stopping],\n",
        "                            verbose=1)\n",
        "\n",
        "# Evaluate tumor grade model\n",
        "y_grade_pred_nn = nn_grade.predict(X_test_scaled)\n",
        "y_grade_pred_classes = np.argmax(y_grade_pred_nn, axis=1)\n",
        "\n",
        "print(\"\\nTumor Grade Classification Results (Neural Network):\")\n",
        "print(\"Accuracy:\", accuracy_score(y_grade_test, y_grade_pred_classes))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_grade_test, y_grade_pred_classes, target_names=le_grade.classes_))\n",
        "\n",
        "# Plot training history for tumor grade\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_grade.history['accuracy'])\n",
        "plt.plot(history_grade.history['val_accuracy'])\n",
        "plt.title('Tumor Grade Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_grade.history['loss'])\n",
        "plt.plot(history_grade.history['val_loss'])\n",
        "plt.title('Tumor Grade Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4. Compare with previous models\n",
        "def compare_all_models(y_true, y_pred_rf, y_pred_svm, y_pred_nn, model_type):\n",
        "    print(f\"\\nComparison for {model_type}:\")\n",
        "    print(f\"Random Forest Accuracy: {accuracy_score(y_true, y_pred_rf):.4f}\")\n",
        "    print(f\"SVM Accuracy: {accuracy_score(y_true, y_pred_svm):.4f}\")\n",
        "    print(f\"Neural Network Accuracy: {accuracy_score(y_true, y_pred_nn):.4f}\")\n",
        "\n",
        "# Compare all models\n",
        "compare_all_models(y_type_test, y_type_pred, y_type_pred_svm, y_type_pred_classes, \"Cancer Type Classification\")\n",
        "compare_all_models(y_grade_test, y_grade_pred, y_grade_pred_svm, y_grade_pred_classes, \"Tumor Grade Classification\")"
      ],
      "metadata": {
        "id": "I3WwwEiZGGim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 3 3. EDA_and_Comparative_machine_learning_analysis_of_ brain_cancer (Brain_GSE50161)"
      ],
      "metadata": {
        "id": "P-QrCrvsHpKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: chaeck expression data for any N or Nan in  Brain_GSE50161g, the expression data is from the third column (column2),  third row (row2) and goes to row5466 and column131, its python rows and columns so thrid column is column2, third row is row2. make sure number of Nas or Nans are printed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Assuming Brain_GSE50161g is your DataFrame\n",
        "\n",
        "Brain_GSE50161g = pd.read_csv(\"Brain_GSE50161g.csv\", header=None)\n",
        "print(Brain_GSE50161g)\n",
        "\n",
        "nan_count = Brain_GSE50161g.iloc[2:5467, 2:132].isnull().sum().sum()\n",
        "n_count = (Brain_GSE50161g.iloc[2:5467, 2:132] == 'N').sum().sum()\n",
        "\n",
        "\n",
        "print(f\"Number of NaN values: {nan_count}\")\n",
        "print(f\"Number of 'N' values: {n_count}\")"
      ],
      "metadata": {
        "id": "W2XchW-DGL9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "Brain_GSE50161g = pd.read_csv('Brain_GSE50161g.csv')\n",
        "\n",
        "# 1. Print dimensions of the data\n",
        "print(f\"Dimensions of the data: {Brain_GSE50161g.shape}\")\n",
        "\n",
        "# 2. Extract relevant parts of the data\n",
        "sample_ids6 = Brain_GSE50161g.iloc[0, 2:132].values    # Sample IDs in row 1 (Python index 0)\n",
        "sample_types6 = Brain_GSE50161g.iloc[1, 2:132].values  # Sample types in row 2 (Python index 1)\n",
        "sample_grades6 = Brain_GSE50161g.iloc[2, 2:132].values  # Sample grades in row 3 (Python index 2)\n",
        "probe_ids6 = Brain_GSE50161g.iloc[3:, 0].values         # Probe IDs starting from row 4 (Python index 3)\n",
        "gene_symbols6 = Brain_GSE50161g.iloc[3:, 1].values      # Gene symbols starting from row 4\n",
        "gene_expression6 = Brain_GSE50161g.iloc[3:, 2:132].T    # Transpose to have samples as rows\n",
        "\n",
        "# 3. Print the first few sample types and grades\n",
        "print(\"First few sample types (Sample IDs):\")\n",
        "print(sample_ids6[:5])\n",
        "print(\"First few sample grades:\")\n",
        "print(sample_types6[:5])\n",
        "\n",
        "# 4. Set row and column names for the gene expression matrix\n",
        "gene_expression6.columns = probe_ids6\n",
        "gene_expression6.index = sample_ids6\n",
        "\n",
        "# 5. Convert gene expression data to numeric\n",
        "gene_expression6 = gene_expression6.apply(pd.to_numeric)\n",
        "\n",
        "# 6. Perform PCA\n",
        "pca = PCA()\n",
        "pca_result6 = pca.fit_transform(gene_expression6)\n",
        "\n",
        "# 7. Extract PC1 and PC2\n",
        "pc_data6 = pd.DataFrame({\n",
        "    'PC1': pca_result6[:, 0],\n",
        "    'PC2': pca_result6[:, 1],\n",
        "    'Type': sample_types6,\n",
        "    'Grade': sample_grades6\n",
        "})\n",
        "\n",
        "# 8. Print the structure of pc_data6\n",
        "print(\"Structure of pc_data6:\")\n",
        "print(pc_data6.info())\n",
        "\n",
        "# 9. Calculate variance explained\n",
        "var_explained6 = pca.explained_variance_ratio_\n",
        "\n",
        "# 10. Plot PCA results colored by Type\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='Type', data=pc_data6, s=100, alpha=0.7)\n",
        "plt.title(f'PCA of Brain Cancer Gene Expression Data (GSE50161) by Type')\n",
        "plt.xlabel(f'PC1 ({var_explained6[0] * 100:.2f}% variance explained)')\n",
        "plt.ylabel(f'PC2 ({var_explained6[1] * 100:.2f}% variance explained)')\n",
        "plt.legend(title='Sample Type')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 11. Plot PCA results colored by Grade\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='Grade', data=pc_data6, s=100, alpha=0.7)\n",
        "plt.title(f'PCA of Brain Cancer Gene Expression Data (GSE50161) by Grade')\n",
        "plt.xlabel(f'PC1 ({var_explained6[0] * 100:.2f}% variance explained)')\n",
        "plt.ylabel(f'PC2 ({var_explained6[1] * 100:.2f}% variance explained)')\n",
        "plt.legend(title='Sample Grade')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 12. Print summary of PCA\n",
        "print(\"PCA Summary:\")\n",
        "print(f\"Variance explained by first two components: PC1 = {var_explained6[0] * 100:.2f}%, PC2 = {var_explained6[1] * 100:.2f}%\")\n",
        "\n",
        "# 13. Display the first few rows of the PC data\n",
        "print(\"First few rows of PC data:\")\n",
        "print(pc_data6.head())"
      ],
      "metadata": {
        "id": "H0NrmZgoIASp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hierarchical Clustering with Heatmap of AFFX and controls to judge whether data is normalised\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('Brain_GSE50161g.csv')\n",
        "\n",
        "# Determine the actual dimensions of your data\n",
        "num_rows = df.shape[0]\n",
        "num_cols = df.shape[1]\n",
        "\n",
        "# Extract sample data (adjust indices based on your actual data structure)\n",
        "# Assuming the data starts from row 3 and column 3\n",
        "sample_data = df.iloc[2:num_rows, 2:num_cols].astype(float)\n",
        "\n",
        "# Extract probe IDs and gene symbols\n",
        "probe_ids = df.iloc[2:num_rows, 0]\n",
        "gene_symbols = df.iloc[2:num_rows, 1]\n",
        "\n",
        "# Extract sample names, types, and grades\n",
        "sample_names = df.columns[2:num_cols]\n",
        "sample_types = df.iloc[0, 2:num_cols]\n",
        "sample_grades = df.iloc[1, 2:num_cols]\n",
        "\n",
        "# Filter for AFFX probes\n",
        "affx_mask = probe_ids.str.contains('AFFX', case=False, na=False)\n",
        "affx_data = sample_data[affx_mask]\n",
        "affx_probe_ids = probe_ids[affx_mask]\n",
        "\n",
        "# Create a DataFrame with AFFX probe data\n",
        "affx_df = pd.DataFrame(affx_data.values, index=affx_probe_ids, columns=sample_names)\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(20, 10))\n",
        "sns.heatmap(affx_df, cmap='coolwarm', center=0, cbar_kws={'label': 'Expression Value'})\n",
        "plt.title('Heatmap of AFFX Probes Across Brain Samples')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('AFFX Probe IDs')\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print some statistics\n",
        "print(f\"Total number of AFFX probes: {len(affx_probe_ids)}\")\n",
        "print(\"\\nFirst 10 AFFX probe IDs:\")\n",
        "print(affx_probe_ids[:10].tolist())\n",
        "\n",
        "# Calculate and print average expression for each AFFX probe\n",
        "avg_expression = affx_df.mean(axis=1).sort_values(ascending=False)\n",
        "print(\"\\nTop 10 AFFX probes by average expression:\")\n",
        "print(avg_expression.head(10))\n",
        "\n",
        "print(\"\\nBottom 10 AFFX probes by average expression:\")\n",
        "print(avg_expression.tail(10))"
      ],
      "metadata": {
        "id": "s8Bftk9cKciP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THE MACHINE LEARNING"
      ],
      "metadata": {
        "id": "wqCgclLCKfn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrected Data Preprocessing for Brain Cancer Gene Expression Analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('Brain_GSE50161g.csv')\n",
        "\n",
        "# Extract features (gene expression values)\n",
        "# Adjusting the row indices to start one row lower\n",
        "X = df.iloc[3:, 2:153].T  # Transpose to get samples as rows\n",
        "X.index = df.columns[2:153]  # Set sample names as index\n",
        "X.columns = df.iloc[3:, 0]  # Set probe_id as column names\n",
        "\n",
        "# Extract labels - shifting down by one row\n",
        "y_type = df.iloc[1, 2:153]  # Changed from 0 to 1\n",
        "y_grade = df.iloc[2, 2:153].astype(str)  # Changed from 1 to 2\n",
        "\n",
        "# Create a mapping of probe_id to gene symbol - adjusted for the row shift\n",
        "gene_map = dict(zip(df.iloc[3:, 0], df.iloc[3:, 1]))\n",
        "\n",
        "# Encode cancer types and grades\n",
        "le_type = LabelEncoder()\n",
        "le_grade = LabelEncoder()\n",
        "y_type_encoded = le_type.fit_transform(y_type)\n",
        "y_grade_encoded = le_grade.fit_transform(y_grade)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_type_train, y_type_test, y_grade_train, y_grade_test = train_test_split(\n",
        "    X, y_type_encoded, y_grade_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Print information about the processed data\n",
        "print(\"Data preprocessed and split into training and test sets.\")\n",
        "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
        "print(f\"Test set shape: {X_test_scaled.shape}\")\n",
        "print(f\"Cancer types: {le_type.classes_}\")\n",
        "print(f\"Tumor grades: {le_grade.classes_}\")\n",
        "\n",
        "# Optional: Print first few rows of cancer types and grades to verify\n",
        "print(\"\\nFirst few cancer types:\")\n",
        "print(y_type[:5])\n",
        "print(\"\\nFirst few grades:\")\n",
        "print(y_grade[:5])"
      ],
      "metadata": {
        "id": "Nq_u59rZKiNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine Learning Analysis for Brain Cancer Gene Expression Data\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Using the preprocessed data from previous code\n",
        "# Assuming we have: X_train_scaled, X_test_scaled, y_type_train, y_type_test, y_grade_train, y_grade_test\n",
        "\n",
        "# 1. Train and evaluate cancer type classifier\n",
        "rf_type = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_type.fit(X_train_scaled, y_type_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_type_pred = rf_type.predict(X_test_scaled)\n",
        "\n",
        "print(\"Cancer Type Classification Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_type_test, y_type_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_type_test, y_type_pred, target_names=le_type.classes_))\n",
        "\n",
        "# Confusion Matrix for cancer types\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_type = confusion_matrix(y_type_test, y_type_pred)\n",
        "sns.heatmap(cm_type, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le_type.classes_,\n",
        "            yticklabels=le_type.classes_)\n",
        "plt.title('Confusion Matrix - Cancer Types')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# 2. Train and evaluate tumor grade classifier\n",
        "rf_grade = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_grade.fit(X_train_scaled, y_grade_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_grade_pred = rf_grade.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nTumor Grade Classification Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_grade_test, y_grade_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_grade_test, y_grade_pred, target_names=le_grade.classes_))\n",
        "\n",
        "# Confusion Matrix for tumor grades\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_grade = confusion_matrix(y_grade_test, y_grade_pred)\n",
        "sns.heatmap(cm_grade, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le_grade.classes_,\n",
        "            yticklabels=le_grade.classes_)\n",
        "plt.title('Confusion Matrix - Tumor Grades')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# 3. Feature Importance Analysis\n",
        "# For cancer types\n",
        "feature_importance_type = pd.DataFrame({\n",
        "    'gene': X.columns,\n",
        "    'importance': rf_type.feature_importances_\n",
        "})\n",
        "feature_importance_type = feature_importance_type.sort_values('importance', ascending=False)\n",
        "\n",
        "# For tumor grades\n",
        "feature_importance_grade = pd.DataFrame({\n",
        "    'gene': X.columns,\n",
        "    'importance': rf_grade.feature_importances_\n",
        "})\n",
        "feature_importance_grade = feature_importance_grade.sort_values('importance', ascending=False)\n",
        "\n",
        "# Print top 10 important genes for each classification\n",
        "print(\"\\nTop 10 Important Genes for Cancer Type Classification:\")\n",
        "for i, row in feature_importance_type.head(10).iterrows():\n",
        "    gene_symbol = gene_map.get(row['gene'], row['gene'])\n",
        "    print(f\"{gene_symbol}: {row['importance']:.4f}\")\n",
        "\n",
        "print(\"\\nTop 10 Important Genes for Tumor Grade Classification:\")\n",
        "for i, row in feature_importance_grade.head(10).iterrows():\n",
        "    gene_symbol = gene_map.get(row['gene'], row['gene'])\n",
        "    print(f\"{gene_symbol}: {row['importance']:.4f}\")"
      ],
      "metadata": {
        "id": "TYvazFBZK34e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM Analysis for Brain Cancer Gene Expression Data\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Cancer Type Classification with SVM\n",
        "print(\"Training SVM for Cancer Type Classification...\")\n",
        "svm_type = SVC(kernel='linear', random_state=42)\n",
        "svm_type.fit(X_train_scaled, y_type_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_type_pred_svm = svm_type.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nCancer Type Classification Results (SVM):\")\n",
        "print(\"Accuracy:\", accuracy_score(y_type_test, y_type_pred_svm))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_type_test, y_type_pred_svm, target_names=le_type.classes_))\n",
        "\n",
        "# Confusion Matrix for cancer types (SVM)\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_type_svm = confusion_matrix(y_type_test, y_type_pred_svm)\n",
        "sns.heatmap(cm_type_svm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le_type.classes_,\n",
        "            yticklabels=le_type.classes_)\n",
        "plt.title('Confusion Matrix - Cancer Types (SVM)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# 2. Tumor Grade Classification with SVM\n",
        "print(\"\\nTraining SVM for Tumor Grade Classification...\")\n",
        "svm_grade = SVC(kernel='linear', random_state=42)\n",
        "svm_grade.fit(X_train_scaled, y_grade_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_grade_pred_svm = svm_grade.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nTumor Grade Classification Results (SVM):\")\n",
        "print(\"Accuracy:\", accuracy_score(y_grade_test, y_grade_pred_svm))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_grade_test, y_grade_pred_svm, target_names=le_grade.classes_))\n",
        "\n",
        "# Confusion Matrix for tumor grades (SVM)\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_grade_svm = confusion_matrix(y_grade_test, y_grade_pred_svm)\n",
        "sns.heatmap(cm_grade_svm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le_grade.classes_,\n",
        "            yticklabels=le_grade.classes_)\n",
        "plt.title('Confusion Matrix - Tumor Grades (SVM)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# 3. Compare SVM vs Random Forest\n",
        "def compare_models(y_true, y_pred_rf, y_pred_svm, model_type):\n",
        "    print(f\"\\nComparison for {model_type}:\")\n",
        "    print(f\"Random Forest Accuracy: {accuracy_score(y_true, y_pred_rf):.4f}\")\n",
        "    print(f\"SVM Accuracy: {accuracy_score(y_true, y_pred_svm):.4f}\")\n",
        "\n",
        "    # Creating a DataFrame for easier comparison\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'True Labels': y_true,\n",
        "        'RF Predictions': y_pred_rf,\n",
        "        'SVM Predictions': y_pred_svm\n",
        "    })\n",
        "\n",
        "    # Find where models disagree\n",
        "    disagreements = comparison_df[comparison_df['RF Predictions'] != comparison_df['SVM Predictions']]\n",
        "    print(f\"\\nNumber of disagreements between models: {len(disagreements)}\")\n",
        "\n",
        "# Compare models for both cancer type and grade\n",
        "compare_models(y_type_test, y_type_pred, y_type_pred_svm, \"Cancer Type Classification\")\n",
        "compare_models(y_grade_test, y_grade_pred, y_grade_pred_svm, \"Tumor Grade Classification\")\n",
        "\n",
        "# 4. Feature Importance for SVM\n",
        "# For linear SVM, feature importance can be derived from the coefficients\n",
        "def get_svm_feature_importance(svm_model, feature_names, class_labels):\n",
        "    importance_per_class = {}\n",
        "    for i, class_label in enumerate(class_labels):\n",
        "        if len(class_labels) == 2 and i == 1:\n",
        "            # For binary classification, we only have one set of coefficients\n",
        "            continue\n",
        "        coef = svm_model.coef_[i] if len(class_labels) > 2 else svm_model.coef_[0]\n",
        "        importance = pd.DataFrame({\n",
        "            'gene': feature_names,\n",
        "            'importance': np.abs(coef)\n",
        "        })\n",
        "        importance_per_class[class_label] = importance.sort_values('importance', ascending=False)\n",
        "    return importance_per_class\n",
        "\n",
        "# Get feature importance for cancer types\n",
        "type_importance_svm = get_svm_feature_importance(svm_type, X.columns, le_type.classes_)\n",
        "\n",
        "print(\"\\nTop 10 Important Genes for Cancer Type Classification (SVM):\")\n",
        "for class_label, importance_df in type_importance_svm.items():\n",
        "    print(f\"\\nFor {class_label}:\")\n",
        "    for i, row in importance_df.head(10).iterrows():\n",
        "        gene_symbol = gene_map.get(row['gene'], row['gene'])\n",
        "        print(f\"{gene_symbol}: {row['importance']:.4f}\")"
      ],
      "metadata": {
        "id": "mmNRzZQ5LAaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network Analysis for Brain Cancer Gene Expression Data\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert labels to categorical format for Keras\n",
        "y_type_train_cat = to_categorical(y_type_train)\n",
        "y_type_test_cat = to_categorical(y_type_test)\n",
        "y_grade_train_cat = to_categorical(y_grade_train)\n",
        "y_grade_test_cat = to_categorical(y_grade_test)\n",
        "\n",
        "# 1. Define function to create model\n",
        "def create_model(input_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Dense(256, activation='relu', input_dim=input_dim),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(output_dim, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 2. Train and evaluate cancer type classifier\n",
        "print(\"Training Neural Network for Cancer Type Classification...\")\n",
        "nn_type = create_model(X_train_scaled.shape[1], len(le_type.classes_))\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "history_type = nn_type.fit(X_train_scaled, y_type_train_cat,\n",
        "                          validation_split=0.2,\n",
        "                          epochs=100,\n",
        "                          batch_size=32,\n",
        "                          callbacks=[early_stopping],\n",
        "                          verbose=1)\n",
        "\n",
        "# Evaluate cancer type model\n",
        "y_type_pred_nn = nn_type.predict(X_test_scaled)\n",
        "y_type_pred_classes = np.argmax(y_type_pred_nn, axis=1)\n",
        "\n",
        "print(\"\\nCancer Type Classification Results (Neural Network):\")\n",
        "print(\"Accuracy:\", accuracy_score(y_type_test, y_type_pred_classes))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_type_test, y_type_pred_classes, target_names=le_type.classes_))\n",
        "\n",
        "# Plot training history for cancer type\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_type.history['accuracy'])\n",
        "plt.plot(history_type.history['val_accuracy'])\n",
        "plt.title('Cancer Type Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_type.history['loss'])\n",
        "plt.plot(history_type.history['val_loss'])\n",
        "plt.title('Cancer Type Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Train and evaluate tumor grade classifier\n",
        "print(\"\\nTraining Neural Network for Tumor Grade Classification...\")\n",
        "nn_grade = create_model(X_train_scaled.shape[1], len(le_grade.classes_))\n",
        "\n",
        "history_grade = nn_grade.fit(X_train_scaled, y_grade_train_cat,\n",
        "                            validation_split=0.2,\n",
        "                            epochs=100,\n",
        "                            batch_size=32,\n",
        "                            callbacks=[early_stopping],\n",
        "                            verbose=1)\n",
        "\n",
        "# Evaluate tumor grade model\n",
        "y_grade_pred_nn = nn_grade.predict(X_test_scaled)\n",
        "y_grade_pred_classes = np.argmax(y_grade_pred_nn, axis=1)\n",
        "\n",
        "print(\"\\nTumor Grade Classification Results (Neural Network):\")\n",
        "print(\"Accuracy:\", accuracy_score(y_grade_test, y_grade_pred_classes))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_grade_test, y_grade_pred_classes, target_names=le_grade.classes_))\n",
        "\n",
        "# Plot training history for tumor grade\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_grade.history['accuracy'])\n",
        "plt.plot(history_grade.history['val_accuracy'])\n",
        "plt.title('Tumor Grade Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_grade.history['loss'])\n",
        "plt.plot(history_grade.history['val_loss'])\n",
        "plt.title('Tumor Grade Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4. Compare with previous models\n",
        "def compare_all_models(y_true, y_pred_rf, y_pred_svm, y_pred_nn, model_type):\n",
        "    print(f\"\\nComparison for {model_type}:\")\n",
        "    print(f\"Random Forest Accuracy: {accuracy_score(y_true, y_pred_rf):.4f}\")\n",
        "    print(f\"SVM Accuracy: {accuracy_score(y_true, y_pred_svm):.4f}\")\n",
        "    print(f\"Neural Network Accuracy: {accuracy_score(y_true, y_pred_nn):.4f}\")\n",
        "\n",
        "# Compare all models\n",
        "compare_all_models(y_type_test, y_type_pred, y_type_pred_svm, y_type_pred_classes, \"Cancer Type Classification\")\n",
        "compare_all_models(y_grade_test, y_grade_pred, y_grade_pred_svm, y_grade_pred_classes, \"Tumor Grade Classification\")"
      ],
      "metadata": {
        "id": "xSrqtja6LJan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MULTI CANCER SECTION"
      ],
      "metadata": {
        "id": "kBK3mbhdLOw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#section1 his script processes two datasets, Breast_GSE45827q and Brain_GSE50161h, to prepare them for analysis. First, it reads the breast cancer dataset from a CSV file and applies quantile transformation to the numeric columns, normalizing their distributions using the inverse of the cumulative distribution function (CDF) from the normal distribution. After transforming the numeric data, it reassigns the original column names to the first row of the DataFrame for clarity. Lastly, it reads the brain cancer\n",
        "# dataset from another CSV file, preserving the first row as column titles, and prints the resulting DataFrames for inspection.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Generate Breast_GSE45827q and transform columns\n",
        "Breast_GSE45827q = pd.read_csv(\"Breast_GSE45827p.csv\", header=0)\n",
        "\n",
        "# Get numeric columns and apply Q transformation\n",
        "numeric_cols = Breast_GSE45827q.select_dtypes(include=[np.number]).columns\n",
        "for col in numeric_cols:\n",
        "    values = Breast_GSE45827q[col].values\n",
        "    ranks = np.argsort(np.argsort(values))\n",
        "    n = len(values)\n",
        "    quantiles = (ranks + 1) / (n + 1)\n",
        "    Breast_GSE45827q[col] = norm.ppf(quantiles)\n",
        "\n",
        "# Move column names to first row\n",
        "old_columns = Breast_GSE45827q.columns.tolist()\n",
        "Breast_GSE45827q.columns = range(len(old_columns))\n",
        "Breast_GSE45827q.loc[-1] = old_columns\n",
        "Breast_GSE45827q.index = Breast_GSE45827q.index + 1\n",
        "Breast_GSE45827q = Breast_GSE45827q.sort_index()\n",
        "print(Breast_GSE45827q)\n",
        "import pandas as pd\n",
        "\n",
        "# Open Brain_GSE50161g.csv as Brain_GSE50161h dataframe\n",
        "import pandas as pd\n",
        "\n",
        "# Open Brain_GSE50161g.csv as Brain_GSE50161h dataframe with the first row as column titles\n",
        "Brain_GSE50161h = pd.read_csv(\"Brain_GSE50161g.csv\", header=0)\n",
        "print(Brain_GSE50161h)"
      ],
      "metadata": {
        "id": "vHJM62zxLp2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Section2\n",
        "# Create a new dataframe Brain_GSE50161i from Brain_GSE50161h\n",
        "Brain_GSE50161i = Brain_GSE50161h.copy()\n",
        "\n",
        "# Change the column names of Brain_GSE50161i to start with 0\n",
        "Brain_GSE50161i.columns = range(0, Brain_GSE50161i.shape[1])\n",
        "\n",
        "# Print the new dataframe to verify\n",
        "print(Brain_GSE50161i)\n"
      ],
      "metadata": {
        "id": "Q2JM-rdSfQoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script defines a function to merge two microarray datasets—one for brain cancer and one for breast cancer—into a single DataFrame. The function merge_microarray_data performs the following steps:\n",
        "\n",
        "Data Preparation: It resets the index for both input DataFrames (brain_df and breast_df) to ensure clean indexing. It then extracts the first three rows as metadata and the remaining rows as probe data for both datasets.\n",
        "\n",
        "Metadata Combination: The function creates a new DataFrame to combine the metadata from both datasets. It retains the first two columns from the breast metadata and appends the corresponding columns from the brain metadata.\n",
        "\n",
        "Probe Data Combination: Similarly, it initializes a DataFrame for the probe data, combining both the breast and brain probe data while preserving their original structure.\n",
        "\n",
        "Final Merge: The metadata and probe data are concatenated vertically to form the final merged DataFrame, breastandbrain.\n",
        "\n",
        "Verification and Output: The script prints the shapes of the original DataFrames and the merged DataFrame for verification. It checks if the total number of columns matches the expected count and outputs the merged DataFrame to a CSV file named breastandbrain.csv.\n",
        "\n",
        "The overall goal is to consolidate the datasets for subsequent analysis, ensuring all relevant information is retained and correctly formatted."
      ],
      "metadata": {
        "id": "-6chTERLfwlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#section3\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def merge_microarray_data(brain_df, breast_df):\n",
        "    # Create new clean indices for both dataframes\n",
        "    brain_clean = brain_df.copy().reset_index(drop=True)\n",
        "    breast_clean = breast_df.copy().reset_index(drop=True)\n",
        "\n",
        "    # Extract metadata (first 3 rows)\n",
        "    breast_metadata = breast_clean.iloc[:3].copy()\n",
        "    brain_metadata = brain_clean.iloc[:3].copy()\n",
        "\n",
        "    # Extract probe data (remaining rows)\n",
        "    breast_probes = breast_clean.iloc[3:].copy().reset_index(drop=True)\n",
        "    brain_probes = brain_clean.iloc[3:].copy().reset_index(drop=True)\n",
        "\n",
        "    # Combine metadata\n",
        "    combined_metadata = pd.DataFrame(index=[0, 1, 2])\n",
        "\n",
        "    # First two columns from breast data\n",
        "    combined_metadata[0] = breast_metadata[0]\n",
        "    combined_metadata[1] = breast_metadata[1]\n",
        "\n",
        "    # Add breast samples\n",
        "    for i in range(2, breast_clean.shape[1]):\n",
        "        combined_metadata[i] = breast_metadata[i]\n",
        "\n",
        "    # Add brain samples\n",
        "    for i in range(2, brain_clean.shape[1]):\n",
        "        new_col = i + breast_clean.shape[1] - 2\n",
        "        combined_metadata[new_col] = brain_metadata[i]\n",
        "\n",
        "    # Combine probe data\n",
        "    combined_probes = pd.DataFrame()\n",
        "\n",
        "    # First two columns from breast data\n",
        "    combined_probes[0] = breast_probes[0]\n",
        "    combined_probes[1] = breast_probes[1]\n",
        "\n",
        "    # Add breast probe data\n",
        "    for i in range(2, breast_clean.shape[1]):\n",
        "        combined_probes[i] = breast_probes[i]\n",
        "\n",
        "    # Add brain probe data\n",
        "    for i in range(2, brain_clean.shape[1]):\n",
        "        new_col = i + breast_clean.shape[1] - 2\n",
        "        combined_probes[new_col] = brain_probes[i]\n",
        "\n",
        "    # Combine metadata and probe data\n",
        "    breastandbrain = pd.concat([combined_metadata, combined_probes], axis=0).reset_index(drop=True)\n",
        "\n",
        "    return breastandbrain\n",
        "\n",
        "# Print info about the dataframes\n",
        "print(f\"Brain_GSE50161i shape: {Brain_GSE50161i.shape}\")\n",
        "print(f\"Breast_GSE45827q shape: {Breast_GSE45827q.shape}\")\n",
        "\n",
        "# Execute the merge\n",
        "breastandbrain = merge_microarray_data(Brain_GSE50161i, Breast_GSE45827q)\n",
        "\n",
        "print(f\"\\nShape of merged dataframe: {breastandbrain.shape}\")\n",
        "print(\"\\nFirst few rows of the merged dataframe:\")\n",
        "print(breastandbrain.iloc[:5, :10])  # Show first 5 rows and 10 columns\n",
        "\n",
        "# Verification\n",
        "print(\"\\nVerification:\")\n",
        "print(f\"Total number of columns: {breastandbrain.shape[1]}\")\n",
        "print(f\"Expected number of columns: {Brain_GSE50161i.shape[1] + Breast_GSE45827q.shape[1] - 2}\")\n",
        "print(f\"Number of rows: {breastandbrain.shape[0]}\")\n",
        "\n",
        "breastandbrain.to_csv(\"breastandbrain.csv\", index=False)"
      ],
      "metadata": {
        "id": "rlH3Dzk4frKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Er4T7FxcgBkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Section5 Check to see if normalisation is needed by checkin control gene heatmap\n",
        "# Hierarchical Clustering with Heatmap of AFFX and controls\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('breastandbrain.csv')\n",
        "\n",
        "# Determine the actual dimensions of your data\n",
        "num_rows = df.shape[0]\n",
        "num_cols = df.shape[1]\n",
        "\n",
        "# Extract sample data (adjust indices based on your actual data structure)\n",
        "# Assuming the data starts from row 3 and column 3\n",
        "sample_data = df.iloc[2:num_rows, 2:num_cols].astype(float)\n",
        "\n",
        "# Extract probe IDs and gene symbols\n",
        "probe_ids = df.iloc[2:num_rows, 0]\n",
        "gene_symbols = df.iloc[2:num_rows, 1]\n",
        "\n",
        "# Extract sample names, types, and grades\n",
        "sample_names = df.columns[2:num_cols]\n",
        "sample_types = df.iloc[0, 2:num_cols]\n",
        "sample_grades = df.iloc[1, 2:num_cols]\n",
        "\n",
        "# Filter for AFFX probes\n",
        "affx_mask = probe_ids.str.contains('AFFX', case=False, na=False)\n",
        "affx_data = sample_data[affx_mask]\n",
        "affx_probe_ids = probe_ids[affx_mask]\n",
        "\n",
        "# Create a DataFrame with AFFX probe data\n",
        "affx_df = pd.DataFrame(affx_data.values, index=affx_probe_ids, columns=sample_names)\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(20, 10))\n",
        "sns.heatmap(affx_df, cmap='coolwarm', center=0, cbar_kws={'label': 'Expression Value'})\n",
        "plt.title('Heatmap of AFFX Probes Across Brain Samples')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('AFFX Probe IDs')\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print some statistics\n",
        "print(f\"Total number of AFFX probes: {len(affx_probe_ids)}\")\n",
        "print(\"\\nFirst 10 AFFX probe IDs:\")\n",
        "print(affx_probe_ids[:10].tolist())\n",
        "\n",
        "# Calculate and print average expression for each AFFX probe\n",
        "avg_expression = affx_df.mean(axis=1).sort_values(ascending=False)\n",
        "print(\"\\nTop 10 AFFX probes by average expression:\")\n",
        "print(avg_expression.head(10))\n",
        "\n",
        "print(\"\\nBottom 10 AFFX probes by average expression:\")\n",
        "print(avg_expression.tail(10))"
      ],
      "metadata": {
        "id": "r0fxzMWs111e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#section6\n",
        "#Normalisation of data acros the 2 combined dataframes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "# Load the data, with low_memory=False to avoid mixed-type warnings\n",
        "df = pd.read_csv('breastandbrain.csv', low_memory=False)\n",
        "\n",
        "# Separate the first three rows (metadata) and the rest of the data\n",
        "metadata_rows = df.iloc[:3]\n",
        "\n",
        "# Keep the first two columns separate\n",
        "first_two_columns = df.iloc[3:, :2]\n",
        "\n",
        "# Expression data starts from column 3 (index 2)\n",
        "expression_data = df.iloc[3:, 2:]\n",
        "\n",
        "# Convert expression data to numeric (coerce errors to NaN)\n",
        "expression_data = expression_data.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Create a QuantileTransformer object\n",
        "transformer = QuantileTransformer(output_distribution='uniform', random_state=0)\n",
        "\n",
        "# Fit the transformer to the expression data (ignoring NaN values)\n",
        "normalized_data = transformer.fit_transform(expression_data)\n",
        "\n",
        "# Create a new DataFrame for the normalized data\n",
        "normalized_df = pd.DataFrame(normalized_data, columns=expression_data.columns)\n",
        "\n",
        "# Combine the first two columns with the normalized data\n",
        "combined_df = pd.concat([first_two_columns.reset_index(drop=True),\n",
        "                         normalized_df], axis=1)\n",
        "\n",
        "# Combine the metadata with the combined data\n",
        "final_df = pd.concat([metadata_rows, combined_df], ignore_index=True)\n",
        "\n",
        "# Save the output as 'breastandbrain_normalized.csv'\n",
        "final_df.to_csv('breastandbrain_normalized.csv', index=False)\n",
        "print(\"Normalization complete and saved as 'breastandbrain_normalized.csv'\")"
      ],
      "metadata": {
        "id": "Yv0E3VmDghIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Section 7 Detect NAz in the dataframe, only in col['1']\n",
        "# Detect Nan vales in data, Assuming 'df' is your DataFrame\n",
        "nan_columns = final_df.columns[final_df.isna().any()].tolist() # Changed df to final_df\n",
        "\n",
        "print(f\"Columns with NaN values: {nan_columns}\")"
      ],
      "metadata": {
        "id": "flm37ZeygvAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hierarchical Clustering with Heatmap of AFFX and controls- chec on normalisation process\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the data, with low_memory=False to avoid mixed-type warnings\n",
        "df = pd.read_csv('breastandbrain_normalized.csv', header=None, low_memory=False)\n",
        "print(df.head())\n",
        "\n",
        "# Separate metadata (Probe IDs and Gene Symbols) and expression data\n",
        "probe_ids = df.iloc[3:, 0]  # Probe IDs start from row 4 (index 3), column 1 (index 0)\n",
        "gene_symbols = df.iloc[3:, 1]  # Gene Symbols in column 2 (index 1)\n",
        "expression_data = df.iloc[3:, 2:]  # Expression data starts from column 3 (index 2)\n",
        "\n",
        "# Convert expression data to numeric (coerce errors to NaN)\n",
        "expression_data = expression_data.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Filter for AFFX probes in the Probe ID column\n",
        "affx_mask = probe_ids.str.contains('AFFX', case=False, na=False)\n",
        "affx_expression_data = expression_data[affx_mask]\n",
        "affx_probe_ids = probe_ids[affx_mask]\n",
        "affx_gene_symbols = gene_symbols[affx_mask]\n",
        "\n",
        "# Create a DataFrame with AFFX probe data\n",
        "affx_df = pd.DataFrame(affx_expression_data.values,\n",
        "                       index=pd.MultiIndex.from_arrays([affx_probe_ids, affx_gene_symbols],\n",
        "                                                       names=['Probe_ID', 'Gene_Symbol']),\n",
        "                       columns=df.iloc[0, 2:])  # Sample names in row 1 (index 0)\n",
        "\n",
        "# Plot the heatmap for AFFX probes\n",
        "plt.figure(figsize=(20, 10))\n",
        "sns.heatmap(affx_df, cmap='coolwarm', center=0, cbar_kws={'label': 'Expression Value'})\n",
        "plt.title('Heatmap of AFFX Probes Across Brain and Breast Samples')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('AFFX Probe IDs')\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print some statistics\n",
        "print(f\"Total number of AFFX probes: {len(affx_probe_ids)}\")\n",
        "print(\"\\nFirst 10 AFFX probe IDs:\")\n",
        "print(affx_probe_ids[:10].tolist())\n",
        "\n",
        "# Calculate and print average expression for each AFFX probe\n",
        "avg_expression = affx_df.mean(axis=1).sort_values(ascending=False)\n",
        "print(\"\\nTop 10 AFFX probes by average expression:\")\n",
        "print(avg_expression.head(10))\n",
        "\n",
        "print(\"\\nBottom 10 AFFX probes by average expression:\")\n",
        "print(avg_expression.tail(10))"
      ],
      "metadata": {
        "id": "g04GN3F-g83I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PCA analysis with and without normalization for comparison\n",
        "#PCA ANALYSIS WITHOUT NORMALISATION\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "breastandbrain = pd.read_csv('breastandbrain.csv')\n",
        "\n",
        "# 1. Print dimensions of the data\n",
        "print(f\"Dimensions of the data: {breastandbrain.shape}\")\n",
        "\n",
        "# 2. Extract relevant parts of the data\n",
        "sample_ids6 = breastandbrain.iloc[0, 2:283].values    # Sample IDs in row 1 (Python index 0)\n",
        "sample_types6 = breastandbrain.iloc[1, 2:283].values  # Sample types in row 2 (Python index 1)\n",
        "sample_grades6 = breastandbrain.iloc[2, 2:283].values  # Sample grades in row 3 (Python index 2)\n",
        "probe_ids6 = breastandbrain.iloc[3:, 0].values         # Probe IDs starting from row 4 (Python index 3)\n",
        "gene_symbols6 = breastandbrain.iloc[3:, 1].values      # Gene symbols starting from row 4\n",
        "gene_expression6 = breastandbrain.iloc[3:, 2:283].T    # Transpose to have samples as rows\n",
        "\n",
        "# 3. Print the first few sample types and grades\n",
        "print(\"First few sample types (Sample IDs):\")\n",
        "print(sample_ids6[:5])\n",
        "print(\"First few sample grades:\")\n",
        "print(sample_types6[:5])\n",
        "\n",
        "# 4. Set row and column names for the gene expression matrix\n",
        "gene_expression6.columns = probe_ids6\n",
        "gene_expression6.index = sample_ids6\n",
        "\n",
        "# 5. Convert gene expression data to numeric\n",
        "gene_expression6 = gene_expression6.apply(pd.to_numeric)\n",
        "\n",
        "# 6. Perform PCA\n",
        "pca = PCA()\n",
        "pca_result6 = pca.fit_transform(gene_expression6)\n",
        "\n",
        "# 7. Extract PC1 and PC2\n",
        "pc_data6 = pd.DataFrame({\n",
        "    'PC1': pca_result6[:, 0],\n",
        "    'PC2': pca_result6[:, 1],\n",
        "    'Type': sample_types6,\n",
        "    'Grade': sample_grades6\n",
        "})\n",
        "\n",
        "# 8. Print the structure of pc_data6\n",
        "print(\"Structure of pc_data6:\")\n",
        "print(pc_data6.info())\n",
        "\n",
        "# 9. Calculate variance explained\n",
        "var_explained6 = pca.explained_variance_ratio_\n",
        "\n",
        "# 10. Plot PCA results colored by Type\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='Type', data=pc_data6, s=100, alpha=0.7)\n",
        "plt.title(f'PCA of Breast and Brain Cancer Gene Expression Data by Type')\n",
        "plt.xlabel(f'PC1 ({var_explained6[0] * 100:.2f}% variance explained)')\n",
        "plt.ylabel(f'PC2 ({var_explained6[1] * 100:.2f}% variance explained)')\n",
        "plt.legend(title='Sample Type')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 11. Plot PCA results colored by grade\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='Grade', data=pc_data6, s=100, alpha=0.7)\n",
        "plt.title(f'PCA of Breast and Brain Cancer Gene Expression Data by Grade')\n",
        "plt.xlabel(f'PC1 ({var_explained6[0] * 100:.2f}% variance explained)')\n",
        "plt.ylabel(f'PC2 ({var_explained6[1] * 100:.2f}% variance explained)')\n",
        "plt.legend(title='Sample Type')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 12. Print summary of PCA\n",
        "print(\"PCA Summary:\")\n",
        "print(f\"Variance explained by first two components: PC1 = {var_explained6[0] * 100:.2f}%, PC2 = {var_explained6[1] * 100:.2f}%\")\n",
        "\n",
        "# 13. Display the first few rows of the PC data\n",
        "print(\"First few rows of PC data:\")\n",
        "print(pc_data6.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "sREbRQokhFwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PCA ANALYSIS WITHOUT NORMALISATION\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "breastandbrain = pd.read_csv('breastandbrain.csv')\n",
        "\n",
        "# 1. Print dimensions of the data\n",
        "print(f\"Dimensions of the data: {breastandbrain.shape}\")\n",
        "\n",
        "# 2. Extract relevant parts of the data\n",
        "sample_ids6 = breastandbrain.iloc[0, 2:283].values    # Sample IDs in row 1 (Python index 0)\n",
        "sample_types6 = breastandbrain.iloc[1, 2:283].values  # Sample types in row 2 (Python index 1)\n",
        "sample_grades6 = breastandbrain.iloc[2, 2:283].values  # Sample grades in row 3 (Python index 2)\n",
        "probe_ids6 = breastandbrain.iloc[3:, 0].values         # Probe IDs starting from row 4 (Python index 3)\n",
        "gene_symbols6 = breastandbrain.iloc[3:, 1].values      # Gene symbols starting from row 4\n",
        "gene_expression6 = breastandbrain.iloc[3:, 2:283].T    # Transpose to have samples as rows\n",
        "\n",
        "# 3. Print the first few sample types and grades\n",
        "print(\"First few sample types (Sample IDs):\")\n",
        "print(sample_ids6[:5])\n",
        "print(\"First few sample grades:\")\n",
        "print(sample_types6[:5])\n",
        "\n",
        "# 4. Set row and column names for the gene expression matrix\n",
        "gene_expression6.columns = probe_ids6\n",
        "gene_expression6.index = sample_ids6\n",
        "\n",
        "# 5. Convert gene expression data to numeric\n",
        "gene_expression6 = gene_expression6.apply(pd.to_numeric)\n",
        "\n",
        "# 6. Perform PCA\n",
        "pca = PCA()\n",
        "pca_result6 = pca.fit_transform(gene_expression6)\n",
        "\n",
        "# 7. Extract PC1 and PC2\n",
        "pc_data6 = pd.DataFrame({\n",
        "    'PC1': pca_result6[:, 0],\n",
        "    'PC2': pca_result6[:, 1],\n",
        "    'Type': sample_types6,\n",
        "    'Grade': sample_grades6\n",
        "})\n",
        "\n",
        "# 8. Print the structure of pc_data6\n",
        "print(\"Structure of pc_data6:\")\n",
        "print(pc_data6.info())\n",
        "\n",
        "# 9. Calculate variance explained\n",
        "var_explained6 = pca.explained_variance_ratio_\n",
        "\n",
        "# 10. Plot PCA results colored by Type\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='Type', data=pc_data6, s=100, alpha=0.7)\n",
        "plt.title(f'PCA of Breast and Brain Cancer Gene Expression Data by Type')\n",
        "plt.xlabel(f'PC1 ({var_explained6[0] * 100:.2f}% variance explained)')\n",
        "plt.ylabel(f'PC2 ({var_explained6[1] * 100:.2f}% variance explained)')\n",
        "plt.legend(title='Sample Type')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 11. Plot PCA results colored by grade\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='Grade', data=pc_data6, s=100, alpha=0.7)\n",
        "plt.title(f'PCA of Breast and Brain Cancer Gene Expression Data by Grade')\n",
        "plt.xlabel(f'PC1 ({var_explained6[0] * 100:.2f}% variance explained)')\n",
        "plt.ylabel(f'PC2 ({var_explained6[1] * 100:.2f}% variance explained)')\n",
        "plt.legend(title='Sample Type')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 12. Print summary of PCA\n",
        "print(\"PCA Summary:\")\n",
        "print(f\"Variance explained by first two components: PC1 = {var_explained6[0] * 100:.2f}%, PC2 = {var_explained6[1] * 100:.2f}%\")\n",
        "\n",
        "# 13. Display the first few rows of the PC data\n",
        "print(\"First few rows of PC data:\")\n",
        "print(pc_data6.head())"
      ],
      "metadata": {
        "id": "bMjot4u4haP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#section 11\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "df = final_df\n",
        "print(df.head()) # Use head() to display the first few rows of the dataframe"
      ],
      "metadata": {
        "id": "XhuE_plJhczL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The machine learning model implemented is a Support Vector Machine (SVM) with a linear kernel, designed for classifying breast cancer types and tumor grades from gene expression data. The model leverages class weights to address class imbalance, ensuring that minority classes are given more importance during training. Performance is evaluated using metrics such as accuracy, classification reports,\n",
        "#and confusion matrices, providing insights into the model's effectiveness across different classes.\n",
        "#mode1 1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Data Loading and Preprocessing\n",
        "\n",
        "breastandbrain1 = final_df\n",
        "# Load the data\n",
        "df = breastandbrain1\n",
        "print(\"First few rows of the dataframe:\")\n",
        "print(df.head())\n",
        "\n",
        "# Extract features (gene expression values)\n",
        "X = df.iloc[3:, 2:283].T  # Transpose to get samples as rows and genes as columns\n",
        "X.index = df.iloc[0, 2:283]  # Set Sample_IDs as index\n",
        "X.columns = df.iloc[3:, 0]  # Set Probe_IDs as column names\n",
        "\n",
        "# Extract labels\n",
        "y_type = df.iloc[1, 2:283]  # Sample type is in the second row\n",
        "y_grade = df.iloc[2, 2:283].astype(str)  # Grade is in the third row\n",
        "\n",
        "# Create a mapping of probe_id to gene symbol (if needed)\n",
        "gene_map = dict(zip(df.iloc[3:, 0], df.iloc[3:, 1]))\n",
        "\n",
        "# Encode cancer types and grades\n",
        "le_type = LabelEncoder()\n",
        "le_grade = LabelEncoder()\n",
        "y_type_encoded = le_type.fit_transform(y_type)\n",
        "y_grade_encoded = le_grade.fit_transform(y_grade)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_type_train, y_type_test, y_grade_train, y_grade_test = train_test_split(\n",
        "    X, y_type_encoded, y_grade_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\nData preprocessing completed:\")\n",
        "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
        "print(f\"Test set shape: {X_test_scaled.shape}\")\n",
        "print(f\"Cancer types: {le_type.classes_}\")\n",
        "print(f\"Tumor grades: {le_grade.classes_}\")\n",
        "\n",
        "# 2. Cancer Type Classification with SVM\n",
        "print(\"\\nTraining SVM for Cancer Type Classification...\")\n",
        "svm_type = SVC(kernel='linear', random_state=42)\n",
        "svm_type.fit(X_train_scaled, y_type_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_type_pred_svm = svm_type.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nCancer Type Classification Results (SVM):\")\n",
        "print(\"Accuracy:\", accuracy_score(y_type_test, y_type_pred_svm))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_type_test, y_type_pred_svm, target_names=le_type.classes_))\n",
        "\n",
        "# Confusion Matrix for cancer types (SVM)\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_type_svm = confusion_matrix(y_type_test, y_type_pred_svm)\n",
        "sns.heatmap(cm_type_svm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le_type.classes_,\n",
        "            yticklabels=le_type.classes_)\n",
        "plt.title('Confusion Matrix - Cancer Types (SVM)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# 3. Tumor Grade Classification with SVM\n",
        "print(\"\\nTraining SVM for Tumor Grade Classification...\")\n",
        "svm_grade = SVC(kernel='linear', random_state=42)\n",
        "svm_grade.fit(X_train_scaled, y_grade_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_grade_pred_svm = svm_grade.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nTumor Grade Classification Results (SVM):\")\n",
        "print(\"Accuracy:\", accuracy_score(y_grade_test, y_grade_pred_svm))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_grade_test, y_grade_pred_svm, target_names=le_grade.classes_))\n",
        "\n",
        "# Confusion Matrix for tumor grades (SVM)\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_grade_svm = confusion_matrix(y_grade_test, y_grade_pred_svm)\n",
        "sns.heatmap(cm_grade_svm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le_grade.classes_,\n",
        "            yticklabels=le_grade.classes_)\n",
        "plt.title('Confusion Matrix - Tumor Grades (SVM)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# 4. Feature Importance Analysis\n",
        "def get_svm_feature_importance(svm_model, feature_names, class_labels):\n",
        "    importance_per_class = {}\n",
        "    for i, class_label in enumerate(class_labels):\n",
        "        if len(class_labels) == 2 and i == 1:\n",
        "            continue\n",
        "        coef = svm_model.coef_[i] if len(class_labels) > 2 else svm_model.coef_[0]\n",
        "        import sys"
      ],
      "metadata": {
        "id": "-x46ihwNhoO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The model employs a Random Forest Classifier to analyze breast cancer gene expression data, specifically addressing class imbalance through the use of computed class weights for both cancer types and tumor grades. By fitting the model with these weights, it enhances the model's sensitivity to underrepresented classes during training. After training, the model evaluates its performance using accuracy metrics, classification reports, and confusion matrices, visualizing the results to better understand prediction accuracy across different categories.\n",
        "#Additionally, it provides insights into feature importance, identifying the most influential genes for each classification tas\n",
        "#MODEL4\n",
        "# weighted Machine Learning Analysis for Breast Cancer Gene Expression Data\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Using the preprocessed data from previous code\n",
        "# Assuming we have: X_train_scaled, X_test_scaled, y_type_train, y_type_test, y_grade_train, y_grade_test\n",
        "\n",
        "# 1. Calculate class weights for cancer types\n",
        "class_weights_type = compute_class_weight('balanced', classes=np.unique(y_type_train), y=y_type_train)\n",
        "class_weight_dict_type = dict(enumerate(class_weights_type))\n",
        "\n",
        "# Train and evaluate cancer type classifier\n",
        "rf_type = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=class_weight_dict_type)\n",
        "rf_type.fit(X_train_scaled, y_type_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_type_pred = rf_type.predict(X_test_scaled)\n",
        "\n",
        "print(\"Cancer Type Classification Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_type_test, y_type_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_type_test, y_type_pred, target_names=le_type.classes_))\n",
        "\n",
        "# Confusion Matrix for cancer types\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_type = confusion_matrix(y_type_test, y_type_pred)\n",
        "sns.heatmap(cm_type, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le_type.classes_,\n",
        "            yticklabels=le_type.classes_)\n",
        "plt.title('Confusion Matrix - Cancer Types')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# 2. Calculate class weights for tumor grades\n",
        "class_weights_grade = compute_class_weight('balanced', classes=np.unique(y_grade_train), y=y_grade_train)\n",
        "class_weight_dict_grade = dict(enumerate(class_weights_grade))\n",
        "\n",
        "# Train and evaluate tumor grade classifier\n",
        "rf_grade = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=class_weight_dict_grade)\n",
        "rf_grade.fit(X_train_scaled, y_grade_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_grade_pred = rf_grade.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nTumor Grade Classification Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_grade_test, y_grade_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_grade_test, y_grade_pred, target_names=le_grade.classes_))\n",
        "\n",
        "# Confusion Matrix for tumor grades\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_grade = confusion_matrix(y_grade_test, y_grade_pred)\n",
        "sns.heatmap(cm_grade, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le_grade.classes_,\n",
        "            yticklabels=le_grade.classes_)\n",
        "plt.title('Confusion Matrix - Tumor Grades')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# 3. Feature Importance Analysis\n",
        "# For cancer types\n",
        "feature_importance_type = pd.DataFrame({\n",
        "    'gene': X.columns,\n",
        "    'importance': rf_type.feature_importances_\n",
        "})\n",
        "feature_importance_type = feature_importance_type.sort_values('importance', ascending=False)\n",
        "\n",
        "# For tumor grades\n",
        "feature_importance_grade = pd.DataFrame({\n",
        "    'gene': X.columns,\n",
        "    'importance': rf_grade.feature_importances_\n",
        "})\n",
        "feature_importance_grade = feature_importance_grade.sort_values('importance', ascending=False)\n",
        "\n",
        "# Print top 10 important genes for each classification\n",
        "print(\"\\nTop 10 Important Genes for Cancer Type Classification:\")\n",
        "for i, row in feature_importance_type.head(10).iterrows():\n",
        "    gene_symbol = gene_map.get(row['gene'], row['gene'])\n",
        "    print(f\"{gene_symbol}: {row['importance']:.4f}\")\n",
        "\n",
        "print(\"\\nTop 10 Important Genes for Tumor Grade Classification:\")\n",
        "for i, row in feature_importance_grade.head(10).iterrows():\n",
        "    gene_symbol = gene_map.get(row['gene'], row['gene'])\n",
        "    print(f\"{gene_symbol}: {row['importance']:.4f}\")\n"
      ],
      "metadata": {
        "id": "d0yEgdiChqI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This model implements a neural network using TensorFlow's\n",
        "# Keras API to classify breast cancer types and tumor grades, while addressing class\n",
        " #imbalance through computed class weights. The architecture features multiple dense layers with dropout and batch normalization for improved generalization and reduced overfitting. The model employs early stopping and learning rate reduction strategies during training, enhancing its robustness. After training, the model evaluates its performance using #accuracy metrics, classification reports, and confusion matrices, providing a comprehensive comparison against previous models.\n",
        "\n",
        "# Add these lines to one-hot encode the target variables\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_type_train_cat = to_categorical(y_type_train)\n",
        "y_type_test_cat = to_categorical(y_type_test)\n",
        "y_grade_train_cat = to_categorical(y_grade_train)\n",
        "y_grade_test_cat = to_categorical(y_grade_test)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Compute class weights for both type and grade\n",
        "class_weights_type = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_type_train),\n",
        "    y=y_type_train\n",
        ")\n",
        "class_weights_type_dict = dict(enumerate(class_weights_type))\n",
        "\n",
        "class_weights_grade = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_grade_train),\n",
        "    y=y_grade_train\n",
        ")\n",
        "class_weights_grade_dict = dict(enumerate(class_weights_grade))\n",
        "\n",
        "def create_improved_model(input_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Dense(512, activation='relu', input_dim=input_dim, kernel_regularizer=l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(output_dim, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_model(X_train, y_train, X_test, y_test, class_weights, le_classes, model_name):\n",
        "    model = create_improved_model(X_train.shape[1], y_train.shape[1])\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=15,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=0.00001,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_split=0.2,\n",
        "        epochs=200,\n",
        "        batch_size=16,\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "        class_weight=class_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate model\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    print(f\"\\n{model_name} Classification Results:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test_classes, y_pred_classes))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test_classes, y_pred_classes, target_names=le_classes))\n",
        "\n",
        "      # Plot training history\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title(f'{model_name} Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title(f'{model_name} Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=le_classes,\n",
        "                yticklabels=le_classes)\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "    return model, history, y_pred_classes\n",
        "\n",
        "# Train and evaluate cancer type model\n",
        "print(\"Training Cancer Type Classification Model...\")\n",
        "nn_type, history_type, y_type_pred_classes = train_and_evaluate_model(\n",
        "    X_train_scaled, y_type_train_cat,\n",
        "    X_test_scaled, y_type_test_cat,\n",
        "    class_weights_type_dict, le_type.classes_,\n",
        "    \"Cancer Type\"\n",
        ")\n",
        "\n",
        "# Train and evaluate tumor grade model\n",
        "print(\"\\nTraining Tumor Grade Classification Model...\")\n",
        "nn_grade, history_grade, y_grade_pred_classes = train_and_evaluate_model(\n",
        "    X_train_scaled, y_grade_train_cat,\n",
        "    X_test_scaled, y_grade_test_cat,\n",
        "    class_weights_grade_dict, le_grade.classes_,\n",
        "    \"Tumor Grade\"\n",
        ")\n",
        "\n",
        "# Compare with previous models\n",
        "def compare_all_models(y_true, y_pred_rf, y_pred_svm, y_pred_nn_old, y_pred_nn_new, model_type):\n",
        "    y_true_classes = np.argmax(y_true, axis=1)\n",
        "    print(f\"\\nComparison for {model_type}:\")\n",
        "    print(f\"Random Forest Accuracy: {accuracy_score(y_true_classes, y_pred_rf):.4f}\")\n",
        "    print(f\"SVM Accuracy: {accuracy_score(y_true_classes, y_pred_svm):.4f}\")\n",
        "    print(f\"Original Neural Network Accuracy: {accuracy_score(y_true_classes, y_pred_nn_old):.4f}\")\n",
        "    print(f\"Improved Neural Network Accuracy: {accuracy_score(y_true_classes, y_pred_nn_new):.4f}\")"
      ],
      "metadata": {
        "id": "ykApOBFeh0Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This function analyzes the important features identified by a trained SVM model for cancer type and tumor grade classification. It computes the importance of genes based on the SVM coefficients, sorting them to identify the top five positive and negative contributors for each class. The function then evaluates and prints the average expression levels of these genes within the respective class compared to other types, calculating fold\n",
        "#changes for additional insights. Finally, it saves the top 50 important genes for each class to a CSV file for further analysis.\n",
        "import pandas as pd\n",
        "\n",
        "def analyze_important_features(X, y, svm_model, gene_map, class_labels):\n",
        "    # Get feature importance\n",
        "    importance_per_class = {}\n",
        "    for i, class_label in enumerate(class_labels):\n",
        "        if len(class_labels) == 2 and i == 1:\n",
        "            continue\n",
        "        coef = svm_model.coef_[i] if len(class_labels) > 2 else svm_model.coef_[0]\n",
        "        importance = pd.DataFrame({\n",
        "            'gene': X.columns,\n",
        "            'importance': coef  # Note: not using absolute value here\n",
        "        })\n",
        "        importance_per_class[class_label] = importance.sort_values('importance', ascending=False)\n",
        "\n",
        "    # Analyze top genes\n",
        "    print(\"\\nTop Important Genes Analysis:\")\n",
        "    for class_label, importance_df in importance_per_class.items():\n",
        "        print(f\"\\nFor {class_label}:\")\n",
        "\n",
        "        # Get top 5 positive and negative genes\n",
        "        top_positive = importance_df.head(5)\n",
        "        top_negative = importance_df.tail(5).iloc[::-1]\n",
        "\n",
        "        # Analyze expression patterns\n",
        "        for importance_type, top_genes in [(\"Higher in \"+class_label, top_positive),\n",
        "                                             (\"Lower in \"+class_label, top_negative)]:\n",
        "            print(f\"\\n{importance_type}:\")\n",
        "            for _, row in top_genes.iterrows():\n",
        "                gene_id = row['gene']\n",
        "                gene_symbol = gene_map.get(gene_id, gene_id)\n",
        "                importance = row['importance']\n",
        "\n",
        "                # Calculate average expression in this class vs others\n",
        "                mask_this_class = (y == i)\n",
        "                avg_expr_this_class = X[gene_id][mask_this_class].mean()\n",
        "                avg_expr_other = X[gene_id][~mask_this_class].mean()\n",
        "\n",
        "                print(f\"{gene_symbol}: \"\n",
        "                      f\"Avg expression in {class_label}: {avg_expr_this_class:.2f}, \"\n",
        "                      f\"Other types: {avg_expr_other:.2f}, \"\n",
        "                      f\"Fold change: {avg_expr_this_class/avg_expr_other:.2f}\")\n",
        "\n",
        "        # Save top 50 genes to CSV\n",
        "        top_50_genes = importance_df.head(50)\n",
        "        top_50_genes['gene_symbol'] = top_50_genes['gene'].map(gene_map).fillna(top_50_genes['gene'])\n",
        "        top_50_genes.to_csv(f\"{class_label}_top_50_genes.csv\", index=False)\n",
        "        print(f\"\\nTop 50 genes for {class_label} saved to '{class_label}_top_50_genes.csv'.\")\n",
        "\n",
        "# After training the SVM model, call this function:\n",
        "print(\"\\nAnalyzing cancer type classification features:\")\n",
        "analyze_important_features(X, y_type_encoded, svm_type, gene_map, le_type.classes_)\n",
        "\n",
        "print(\"\\nAnalyzing tumor grade classification features:\")\n",
        "analyze_important_features(X, y_grade_encoded, svm_grade, gene_map, le_grade.classes_)"
      ],
      "metadata": {
        "id": "UmelMJELh7f1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}